{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8069bd32",
   "metadata": {},
   "source": [
    "# Часть 2: Реализация Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4884c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.testing import assert_frame_equal\n",
    "from feast import FeatureStore\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5de9581",
   "metadata": {},
   "source": [
    "## 1. Определение фичей для Offline и Online\n",
    "\n",
    "В нашей задаче прогнозирования спроса, \"сущностью\" является не пользователь, а регион (PULocationID). Мы хотим знать характеристики спроса для каждого региона в определенный момент времени.\n",
    "\n",
    "    Фичи для обучения (Offline):\n",
    "    Это те признаки, которые мы уже создали для обучения нашей модели. Они рассчитываются на основе исторических данных.\n",
    "        hour: Час.\n",
    "        dayofweek: День недели.\n",
    "        lag_1h: Спрос час назад.\n",
    "        lag_24h: Спрос 24 часа назад (суточная сезонность).\n",
    "        lag_168h: Спрос неделю назад (недельная сезонность).\n",
    "        rolling_mean_24h: Средний спрос за последние 24 часа.\n",
    "\n",
    "    Фичи для инференса (Online):\n",
    "    Когда мы хотим сделать прогноз на следующий час в реальном времени (например, в 15:00), нам нужны точно такие же фичи, но рассчитанные на основе самых свежих данных:\n",
    "        hour: Час.\n",
    "        dayofweek: День недели.\n",
    "        lag_1h: Реальный спрос в 14:00.\n",
    "        lag_24h: Реальный спрос вчера в 15:00.\n",
    "        lag_168h: Реальный спрос неделю назад в 15:00.\n",
    "        rolling_mean_24h: Средний спрос с 14:00 сегодня до 15:00 вчера.\n",
    "\n",
    "    Фичи, критичные для согласованности:\n",
    "    Все перечисленные фичи являются критичными. Логика их расчета должна быть абсолютно идентичной при обучении (offline) и при реальном использовании (online). Если в offline-расчете lag_24h вы учитывали данные до 14:59:59, а в online — до 15:00:00, это может привести к расхождению (train-serve skew) и ухудшению качества модели в продакшене. Именно эту проблему и решает Feature Store.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35200bda",
   "metadata": {},
   "source": [
    "## 2. Реализация Feature Store с помощью Feast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db552c1",
   "metadata": {},
   "source": [
    "Создание файла с фичами в файле `create_features.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0154c28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>trip_count</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>lag_1h</th>\n",
       "      <th>lag_24h</th>\n",
       "      <th>lag_168h</th>\n",
       "      <th>rolling_mean_24h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-01 06:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-01 07:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-01 08:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-01 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PULocationID         pickup_hour  trip_count  hour  dayofweek  lag_1h  \\\n",
       "0             1 2019-02-01 01:00:00           1     1          4     0.0   \n",
       "1             1 2019-02-01 06:00:00           2     6          4     1.0   \n",
       "2             1 2019-02-01 07:00:00           1     7          4     2.0   \n",
       "3             1 2019-02-01 08:00:00           3     8          4     1.0   \n",
       "4             1 2019-02-01 09:00:00           1     9          4     3.0   \n",
       "\n",
       "   lag_24h  lag_168h  rolling_mean_24h  \n",
       "0      0.0       0.0               0.0  \n",
       "1      0.0       0.0               0.0  \n",
       "2      0.0       0.0               0.0  \n",
       "3      0.0       0.0               0.0  \n",
       "4      0.0       0.0               0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features = pd.read_parquet('nyc_taxi_demand/feature_repo/data/demand_agg_with_ts.parquet')\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2daef28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дата разделения: 2019-02-03 19:05:59.999999\n",
      "Начало данных: 2019-02-01 00:00:00, конец данных: 2019-02-28 23:00:00\n",
      "Команда для материализации feast: feast materialize 2019-02-01 00:00:00 2019-02-03 19:05:59.999999\n"
     ]
    }
   ],
   "source": [
    "min_date = df_features['pickup_hour'].min()\n",
    "max_date = df_features['pickup_hour'].max()\n",
    "date_definition = min_date + (max_date - min_date) * (1 - 0.9)\n",
    "print(f\"Дата разделения: {date_definition}\")\n",
    "print(f\"Начало данных: {min_date}, конец данных: {max_date}\")\n",
    "\n",
    "# feast materialize 2019-01-01T00:00:00 2019-12-31T23:00:00\n",
    "print(f\"Команда для материализации feast: feast materialize {min_date} {date_definition}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eee63192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дата для обучения: 2019-02-01 23:29:05.999999\n"
     ]
    }
   ],
   "source": [
    "date_for_train = min_date + (date_definition - min_date) * (1 - 0.5) * 0.7\n",
    "print(f\"Дата для обучения: {date_for_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59ca1f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дата середины: 2019-02-02 09:32:59.999999\n"
     ]
    }
   ],
   "source": [
    "date_middle = min_date + (date_definition - min_date) * (1 - 0.5)\n",
    "print(f\"Дата середины: {date_middle}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e53423",
   "metadata": {},
   "source": [
    "## 3. Определение features в features.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "405348ed",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# This is an example feature definition file\n",
      "\n",
      "from datetime import timedelta\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "from feast import (\n",
      "    Entity,\n",
      "    FeatureService,\n",
      "    FeatureView,\n",
      "    Field,\n",
      "    FileSource,\n",
      "    Project,\n",
      "    PushSource,\n",
      "    RequestSource,\n",
      "    ValueType\n",
      ")\n",
      "from feast.feature_logging import LoggingConfig\n",
      "from feast.infra.offline_stores.file_source import FileLoggingDestination\n",
      "from feast.on_demand_feature_view import on_demand_feature_view\n",
      "from feast.types import Float32, Float64, Int64\n",
      "\n",
      "\n",
      "project = Project(name=\"nyc_taxi_demand\", description=\"A project for driver statistics\")\n",
      "\n",
      "location = Entity(name=\"PULocationID\", value_type=ValueType.INT64, description=\"Pickup Location ID\")\n",
      "\n",
      "taxi_demand_source = FileSource(\n",
      "    name=\"taxi_demand_source\",\n",
      "    path=\"data/demand_agg_with_ts.parquet\",\n",
      "    timestamp_field=\"pickup_hour\"\n",
      ")\n",
      "\n",
      "demand_features_fv = FeatureView(\n",
      "    name=\"taxi_stats\",\n",
      "    entities=[location],\n",
      "    schema=[\n",
      "        Field(name=\"trip_count\", dtype=Int64),\n",
      "        Field(name=\"lag_1h\", dtype=Float32),\n",
      "        Field(name=\"lag_24h\", dtype=Float32),\n",
      "        Field(name=\"lag_168h\", dtype=Float32),\n",
      "        Field(name=\"hour\", dtype=Int64),\n",
      "        Field(name=\"dayofweek\", dtype=Int64),\n",
      "        Field(name=\"rolling_mean_24h\", dtype=Float32),\n",
      "    ],\n",
      "    online=True,\n",
      "    source=taxi_demand_source,\n",
      "    tags={\"team\": \"demand_forecasting\"},\n",
      ")"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.13/pty.py:95: DeprecationWarning: This process (pid=8636) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    }
   ],
   "source": [
    "cat ./nyc_taxi_demand/feature_repo/features.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0979ed7",
   "metadata": {},
   "source": [
    "## 4-5. Согласованность и проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28c56e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = FeatureStore(repo_path=\"./nyc_taxi_demand/feature_repo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4e213c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Получаем исторические фичи для 6045 событий...\n",
      "Using pickup_hour as the event timestamp. To specify a column explicitly, please name it event_timestamp.\n",
      "Обучающий датасет из Feast:\n",
      "                pickup_hour  PULocationID  trip_count  lag_1h  lag_24h  \\\n",
      "0 2019-02-01 00:00:00+00:00           124          21     0.0      0.0   \n",
      "1 2019-02-01 00:00:00+00:00            22          39     0.0      0.0   \n",
      "2 2019-02-01 00:00:00+00:00           227          31     0.0      0.0   \n",
      "3 2019-02-01 00:00:00+00:00           180          18     0.0      0.0   \n",
      "4 2019-02-01 00:00:00+00:00            51          52     0.0      0.0   \n",
      "\n",
      "   lag_168h  rolling_mean_24h  hour  dayofweek  \n",
      "0       0.0               0.0     0          4  \n",
      "1       0.0               0.0     0          4  \n",
      "2       0.0               0.0     0          4  \n",
      "3       0.0               0.0     0          4  \n",
      "4       0.0               0.0     0          4  \n"
     ]
    }
   ],
   "source": [
    "train_entity_df = df_features[df_features['pickup_hour'] <= date_for_train].copy()\n",
    "train_entity_df = train_entity_df[['pickup_hour', 'PULocationID']]\n",
    "train_entity_df['PULocationID'] = train_entity_df['PULocationID'].astype('int64')\n",
    "\n",
    "print(f\"\\nПолучаем исторические фичи для {len(train_entity_df)} событий...\")\n",
    "\n",
    "features_to_get = [\n",
    "    \"taxi_stats:trip_count\",\n",
    "    \"taxi_stats:lag_1h\",\n",
    "    \"taxi_stats:lag_24h\",\n",
    "    \"taxi_stats:lag_168h\",\n",
    "    \"taxi_stats:rolling_mean_24h\",\n",
    "    \"taxi_stats:hour\",\n",
    "    \"taxi_stats:dayofweek\",\n",
    "]\n",
    "\n",
    "train_df = store.get_historical_features(\n",
    "    entity_df=train_entity_df,\n",
    "    features=features_to_get,\n",
    ").to_df()\n",
    "\n",
    "print(\"Обучающий датасет из Feast:\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcfff020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Получаем исторические фичи для 2507 событий...\n",
      "Using pickup_hour as the event timestamp. To specify a column explicitly, please name it event_timestamp.\n",
      "Тестовый датасет из Feast:\n",
      "                pickup_hour  PULocationID  trip_count  lag_1h  lag_24h  \\\n",
      "0 2019-02-02 00:00:00+00:00           115          16    18.0     14.0   \n",
      "1 2019-02-02 00:00:00+00:00           130         191   224.0    127.0   \n",
      "2 2019-02-02 00:00:00+00:00           220         135   148.0     73.0   \n",
      "3 2019-02-02 00:00:00+00:00            29          45    49.0     20.0   \n",
      "4 2019-02-02 00:00:00+00:00           125         145   190.0    115.0   \n",
      "\n",
      "   lag_168h  rolling_mean_24h  hour  dayofweek  \n",
      "0       0.0         18.291667     0          5  \n",
      "1       0.0        171.250000     0          5  \n",
      "2       0.0        111.166667     0          5  \n",
      "3       0.0         56.833333     0          5  \n",
      "4       0.0        158.750000     0          5  \n"
     ]
    }
   ],
   "source": [
    "test_entity_df = df_features[(df_features['pickup_hour'] > date_for_train) & (df_features['pickup_hour'] <= date_middle)].copy()\n",
    "test_entity_df = test_entity_df[['pickup_hour', 'PULocationID']]\n",
    "test_entity_df['PULocationID'] = test_entity_df['PULocationID'].astype('int64')\n",
    "print(f\"\\nПолучаем исторические фичи для {len(test_entity_df)} событий...\")\n",
    "test_df = store.get_historical_features(\n",
    "    entity_df=test_entity_df,\n",
    "    features=features_to_get,\n",
    ").to_df()\n",
    "print(\"Тестовый датасет из Feast:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b25a2cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Проверяем согласованность фичей...\n",
      "✅ Проверка согласованности пройдена! Фичи идентичны.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nПроверяем согласованность фичей...\")\n",
    "\n",
    "# Подготавливаем эталонный DataFrame\n",
    "direct_features = df_features[df_features['pickup_hour'] <= date_for_train].copy()\n",
    "direct_features['PULocationID'] = direct_features['PULocationID'].astype('int64')\n",
    "\n",
    "# Подготавливаем DataFrame из Feast\n",
    "fs_features = train_df.copy()\n",
    "\n",
    "# Приводим к единому формату\n",
    "# Убираем таймзону из данных Feast для корректного сравнения\n",
    "fs_features['pickup_hour'] = fs_features['pickup_hour'].dt.tz_localize(None)\n",
    "\n",
    "# Приводим ОБЕ колонки к единой точности (nanoseconds), чтобы типы совпадали\n",
    "direct_features['pickup_hour'] = direct_features['pickup_hour'].astype('datetime64[ns]')\n",
    "fs_features['pickup_hour'] = fs_features['pickup_hour'].astype('datetime64[ns]')\n",
    "\n",
    "# Выравниваем колонки и сортируем\n",
    "common_columns = [col for col in direct_features.columns if col in fs_features.columns]\n",
    "direct_features_aligned = direct_features[common_columns].sort_values(by=['pickup_hour', 'PULocationID']).reset_index(drop=True)\n",
    "fs_features_aligned = fs_features[common_columns].sort_values(by=['pickup_hour', 'PULocationID']).reset_index(drop=True)\n",
    "\n",
    "# Сравниваем\n",
    "try:\n",
    "    assert_frame_equal(direct_features_aligned, fs_features_aligned, atol=1e-6)\n",
    "    print(\"✅ Проверка согласованности пройдена! Фичи идентичны.\")\n",
    "except AssertionError as e:\n",
    "    print(\"❌ Проверка согласованности провалена!\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a1db929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Получаем online-фичи...\n",
      "Online-фичи, полученные из Feast:\n",
      "   PULocationID  rolling_mean_24h  trip_count  lag_24h  hour  lag_1h  \\\n",
      "0           130        177.583328         176    163.0    23   240.0   \n",
      "1           220         96.916664         113     90.0    23    93.0   \n",
      "2           125        135.166672         220    116.0    23   238.0   \n",
      "\n",
      "   lag_168h  dayofweek  \n",
      "0     155.0          3  \n",
      "1      92.0          3  \n",
      "2     193.0          3  \n"
     ]
    }
   ],
   "source": [
    "# Симуляция запроса в реальном времени\n",
    "# Допустим, мы хотим сделать прогноз для нескольких регионов прямо сейчас\n",
    "\n",
    "online_entities = [\n",
    "    {\"PULocationID\": 130},\n",
    "    {\"PULocationID\": 220},\n",
    "    {\"PULocationID\": 125},\n",
    "]\n",
    "\n",
    "print(\"\\nПолучаем online-фичи...\")\n",
    "\n",
    "online_features = store.get_online_features(\n",
    "    features=features_to_get,  # тот же список фичей\n",
    "    entity_rows=online_entities\n",
    ").to_dict()\n",
    "\n",
    "# Преобразуем в удобный для просмотра DataFrame\n",
    "online_df = pd.DataFrame.from_dict(online_features)\n",
    "print(\"Online-фичи, полученные из Feast:\")\n",
    "print(online_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
